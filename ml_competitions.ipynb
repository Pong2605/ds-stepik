{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3873b5d1",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a857031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7228c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aa4d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d7a2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39649c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from association_metrics import CramersV\n",
    "import phik\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337d218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c341b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325faf48",
   "metadata": {},
   "source": [
    "# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d3d2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed):\n",
    "    \n",
    "    # python's seeds\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # torch's seeds\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # tensorflow's seed\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "SEED = 2021\n",
    "set_all_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb2e45",
   "metadata": {},
   "source": [
    "# 2.1 üéìüêç –ü–∏—à–µ–º –∏ –æ—Ä–≥–∞–Ω–∏–∑—É–µ–º –∫–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7362974",
   "metadata": {},
   "source": [
    "## üìö –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ üìÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–±–æ—Ç–∞—è –ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, —Å–æ–∑–¥–∞–π —Å–µ–±–µ —Ö–æ—Ç—è –±—ã –±–∞–∑–æ–≤—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\n",
    "\n",
    "# |---competition/\n",
    "#     |---data/ ‚Äî –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "#     |---notebooks/ ‚Äî –Ω–æ—É—Ç–±—É–∫–∏ \n",
    "#     |---models/ ‚Äî –æ–±—É—á–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "#     |---subs/ ‚Äî —Å–∞–±–º–∏—à–Ω —Ñ–∞–π–ª—ã\n",
    "#     |---tmp_data/ ‚Äî –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ —Å–º–µ–ª–æ —É–¥–∞–ª—è—Ç—å\n",
    "#     |---src/ ‚Äî –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ .py —Ñ–∞–π–ª—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776cafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îú‚îÄ‚îÄ LICENSE            <- Open-source license if one is chosen\n",
    "# ‚îú‚îÄ‚îÄ Makefile           <- Makefile with convenience commands like `make data` or `make train`\n",
    "# ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.\n",
    "# ‚îú‚îÄ‚îÄ data\n",
    "# ‚îÇ   ‚îú‚îÄ‚îÄ external       <- Data from third party sources.\n",
    "# ‚îÇ   ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.\n",
    "# ‚îÇ   ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.\n",
    "# ‚îÇ   ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ docs               <- A default mkdocs project; see www.mkdocs.org for details\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "# ‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "# ‚îÇ                         `1.0-jqp-initial-data-exploration`.\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ pyproject.toml     <- Project configuration file with package metadata for \n",
    "# ‚îÇ                         {{ cookiecutter.module_name }} and configuration for tools like black\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "# ‚îÇ   ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "# ‚îÇ                         generated with `pip freeze > requirements.txt`\n",
    "# ‚îÇ\n",
    "# ‚îú‚îÄ‚îÄ setup.cfg          <- Configuration file for flake8\n",
    "# ‚îÇ\n",
    "# ‚îî‚îÄ‚îÄ {{ cookiecutter.module_name }}   <- Source code for use in this project.\n",
    "#     ‚îÇ\n",
    "#     ‚îú‚îÄ‚îÄ __init__.py             <- Makes {{ cookiecutter.module_name }} a Python module\n",
    "#     ‚îÇ\n",
    "#     ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration\n",
    "#     ‚îÇ\n",
    "#     ‚îú‚îÄ‚îÄ dataset.py              <- Scripts to download or generate data\n",
    "#     ‚îÇ\n",
    "#     ‚îú‚îÄ‚îÄ features.py             <- Code to create features for modeling\n",
    "#     ‚îÇ\n",
    "#     ‚îú‚îÄ‚îÄ modeling                \n",
    "#     ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py \n",
    "#     ‚îÇ   ‚îú‚îÄ‚îÄ predict.py          <- Code to run model inference with trained models          \n",
    "#     ‚îÇ   ‚îî‚îÄ‚îÄ train.py            <- Code to train models\n",
    "#     ‚îÇ\n",
    "#     ‚îî‚îÄ‚îÄ plots.py                <- Code to create visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731093f",
   "metadata": {},
   "source": [
    "## –°–æ—Ö—Ä–∞–Ω—è–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –≤ –º–æ–¥–µ–ª—è—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, –µ—Å–ª–∏ –≤ –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä LightGBM) –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏–¥–∞—Ö \n",
    "# –ø–æ–¥–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ä–∞–∑–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ —Ä–∞–∑–Ω—ã–µ!\n",
    "\n",
    "# features = np.unique(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247c885",
   "metadata": {},
   "source": [
    "## –°–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ–ª–≥–æ —Å—á–∏—Ç–∞–ª–∏—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regenerate = True  # –§–ª–∞–≥, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –ª–µ–≥–∫–æ –º–æ–∂–µ—à—å –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å\n",
    "\n",
    "# if regenerate: # –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –ø—Ä–æ—Ö–æ–¥–µ –≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ\n",
    "#      df = make_features(df) # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç—Ä–µ–π–Ω–∞\n",
    "#      df.to_csv('train_with_features.csv', index=False) # –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "#      sub = make_features(sub) # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å–∞–±–º–∏—Ç–∞\n",
    "#      sub.to_csv('test_with_features.csv', index=False) # –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "\n",
    "# else: # –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ –º–æ–∂–Ω–æ —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –±–µ—Å—Ü–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è\n",
    "#      df = pd.read_csv('train_with_features.csv')\n",
    "#      sub = pd.read_csv('test_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd47116",
   "metadata": {},
   "source": [
    "## –°–æ—Ö—Ä–∞–Ω—è–π —Ñ–∞–π–ª—ã –ø–∏–∫–ª–æ–º (df.to_pickle()/pd.read_pickle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# a = {'hello': 'world'}\n",
    "\n",
    "# with open('filename.pickle', 'wb') as handle:\n",
    "#     pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "\n",
    "# print(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e777f50",
   "metadata": {},
   "source": [
    "## –ò—Å–ø–æ–ª—å–∑—É–π –∫–ª–∞—Å—Å—ã –≤–º–µ—Å—Ç–æ —Å–ª–æ–≤–∞—Ä–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Paths:\n",
    "#     model_xgb = '../models/xgb.pickle'\n",
    "#     model_cb  = '../models/cb.pickle'\n",
    "#     model_lgb = '../models/lgb.pickle'\n",
    "    \n",
    "# paths = Paths()\n",
    "\n",
    "# paths.model_xgb  # –≤–º–µ—Å—Ç–æ paths['model_xgb'] –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4cb4f",
   "metadata": {},
   "source": [
    "## –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02850c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–¥–µ–ª–∞–π –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã —Å–≤–æ–µ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞/—Å–∫—Ä–∏–ø—Ç–∞: validation –∏ test. \n",
    "# –ü–µ—Ä–≤—ã–º —Ä–µ–∂–∏–º–æ–º –±—É–¥–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, \n",
    "# –≤—Ç–æ—Ä—ã–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36483d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞–ø—Ä–∏–º–µ—Ä:\n",
    "\n",
    "# X = pd.read_csv('data/train.csv')\n",
    "# y = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "# MODE = 'validation'\n",
    "# if MODE == 'validation':\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                         test_size=0.2,\n",
    "#                                                         random_state=42)\n",
    "# elif MODE == 'test':\n",
    "#     X_train = X\n",
    "#     y_train = y\n",
    "#     X_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59b3ff",
   "metadata": {},
   "source": [
    "## –ò—Å–ø–æ–ª—å–∑—É–π tqdm –¥–ª—è ¬´–ø–æ–¥—Å–≤–µ—Ç–∫–∏¬ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac5c711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 19.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979053a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83e428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aac339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0d5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "891ae3b2",
   "metadata": {},
   "source": [
    "# Tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ddb80c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
