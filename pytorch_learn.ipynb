{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdada  asda asd'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# не трогайте этот код, он необходим для автоматической проверки\n",
    "str_input = 'asdada ! asda, asd.'\n",
    "\n",
    "# ваш код тут\n",
    "\n",
    "str_input = re.sub(r'[,.!]', '', str_input).lower()\n",
    "str_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Синтаксис PyTorch аналогичен синтаксису numpy\n",
    "\n",
    "# torch.tensor() ==> numpy.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n",
      "tensor([[2, 3],\n",
      "        [4, 5]], dtype=torch.int32)\n",
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[2., 3.],\n",
      "        [4., 5.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([2, 3]))\n",
    "\n",
    "print(torch.tensor([[2, 3], [4, 5]], dtype=torch.int32))\n",
    "\n",
    "print(torch.tensor([[2, 3], [4, 5]], dtype=torch.float32))\n",
    "\n",
    "print(torch.tensor([[2, 3], [4, 5]], dtype=torch.float32, requires_grad=True))\n",
    "\n",
    "# print(torch.tensor([[2, 3], [4, 5]], dtype=torch.float32, device=torch.device('cuda:0')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3.],\n",
       "         [4., 5.]],\n",
       "\n",
       "        [[6., 7.],\n",
       "         [8., 9.]]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "3\n",
      "tensor(2., grad_fn=<SelectBackward0>)\n",
      "<class 'torch.Tensor'>\n",
      "2.0\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Свойства и методы tensor\n",
    "\n",
    "tensor = torch.tensor([[[2, 3], [4, 5]],\n",
    "                       [[6, 7], [8, 9]]], \n",
    "                       dtype=torch.float32, \n",
    "                       requires_grad=True)\n",
    "\n",
    "display(tensor)\n",
    "\n",
    "print(tensor.dtype)\n",
    "\n",
    "print(tensor.shape)\n",
    "\n",
    "print(tensor.size())\n",
    "\n",
    "print(tensor.ndim)\n",
    "\n",
    "print(tensor[0, 0, 0])\n",
    "\n",
    "print(type(tensor[0, 0, 0]))\n",
    "\n",
    "print(tensor[0, 0, 0].item())\n",
    "\n",
    "print(type(tensor[0, 0, 0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "torch.float32\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Создание массивов разного размера\n",
    "\n",
    "tensor = torch.zeros([2, 3, 2])\n",
    "print(tensor)\n",
    "print(tensor.dtype)\n",
    "\n",
    "tensor = torch.ones([2, 3, 2])\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float32\n",
      "tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros([2, 3])\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "tensor = torch.zeros_like(tensor)\n",
    "print(tensor)\n",
    "print(tensor.dtype)\n",
    "\n",
    "tensor = torch.full_like(tensor, 7)\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.5000, 3.0000, 3.5000, 4.0000, 4.5000, 5.0000, 5.5000, 6.0000,\n",
       "        6.5000, 7.0000, 7.5000, 8.0000, 8.5000, 9.0000, 9.5000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2, 10, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0],\n",
       "        [0, 5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor([2, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
